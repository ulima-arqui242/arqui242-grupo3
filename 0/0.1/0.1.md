# 0.1. Integrante 1: ANDREA PILAR LLERENA Z√ö√ëIGA

# Arquitectura de Microservicios en Kubernetes

## Introducci√≥n

Este proyecto ilustra una arquitectura basada en microservicios, implementada en un entorno de Kubernetes. Los microservicios son un enfoque arquitect√≥nico que permite desarrollar aplicaciones como un conjunto de servicios peque√±os, aut√≥nomos y desplegables de manera independiente. Este enfoque mejora la escalabilidad, la mantenibilidad y la agilidad del desarrollo.

## ¬øQu√© son los Microservicios?

Los **microservicios** son un estilo arquitect√≥nico que descompone una aplicaci√≥n en componentes peque√±os y manejables. Cada microservicio es responsable de una funcionalidad espec√≠fica y se comunica con otros microservicios a trav√©s de API bien definidas. Esto permite a los equipos trabajar de manera independiente en diferentes partes de la aplicaci√≥n, facilitando el desarrollo, las pruebas y la implementaci√≥n.

### Ventajas de los Microservicios:

- **Escalabilidad**: Los servicios pueden escalarse de forma independiente seg√∫n la demanda.
- **Desarrollo √°gil**: Los equipos pueden desarrollar y desplegar servicios sin afectar al resto de la aplicaci√≥n.
- **Resiliencia**: Si un servicio falla, el resto de la aplicaci√≥n puede seguir funcionando.
- **Flexibilidad tecnol√≥gica**: Cada microservicio puede utilizar diferentes tecnolog√≠as y lenguajes seg√∫n las necesidades.
- **Cambios sin afectar otra parte del negocio**
- **Mantenimiento m√°s f√°cil**
- **Aislamiento de servicios**
  
### Desventajas de los Microservicios:

- **Mayor complejidad**: como los microservicios son distribuidos, gestionar la comunicaci√≥n sobre los servicios puede resultar dif√≠cil. Puede que los desarrolladores tengan que escribir c√≥digo adicional para garantizar una comunicaci√≥n fluida entre los m√≥dulos.
- **Dificultades de implementaci√≥n y control de versiones**: coordinar las implementaciones y gestionar el control de versiones en varios servicios puede resultar complejo y provocar incidencias de compatibilidad.
- **Complejidad de las pruebas**: las pruebas de microservicios implican situaciones complejas, sobre todo cuando se realizan pruebas de integraci√≥n en diferentes servicios. Organizar esta tarea puede ser complicado.
- **Dificultades con la depuraci√≥n**: puede resultar dif√≠cil depurar una aplicaci√≥n que contiene varios microservicios, cada uno con su propio conjunto de registros. Un √∫nico proceso empresarial puede ejecutarse en varias m√°quinas simult√°neamente, lo que agrava la complejidad.
- **Dificultades en la gesti√≥n de datos**: la coherencia de los datos y las transacciones entre varios servicios puede resultar compleja. En la arquitectura de microservicios, la gesti√≥n y la coordinaci√≥n de los datos debe hacerse de forma cuidadosa para proteger la integridad de los datos.
- **Dificultad al estandarizar**


## ¬øQu√© son los Monolitos?

Los **monolitos** son un estilo arquitect√≥nico en el cual una aplicaci√≥n completa se construye como una √∫nica unidad cohesiva. Todas las funciones de la aplicaci√≥n se ejecutan en un mismo proceso y cualquier cambio requiere desplegar toda la aplicaci√≥n nuevamente.

### Ventajas de los Microservicios:

- **Menor repitici√≥n de c√≥digo**
- **End to End Test**
- **Deployment rapidos**
- **Facilidad para controlar versiones:** S√≥lo hay una versi√≥n del sistema a la que se le hacen cambios, lo que facilita el control de versiones y el despliegue.
- **Rendimiento consistente:** Como todos los componentes se ejecutan en un mismo proceso, no se requiere comunicaci√≥n a trav√©s de la red, lo que puede mejorar el rendimiento.
  
### Desventajas de los Microservicios:

- **Escalabilidad limitada:** A medida que la aplicaci√≥n crece, puede volverse dif√≠cil escalarla. Escalar un monolito implica replicar toda la aplicaci√≥n en lugar de escalar solo partes espec√≠ficas.
Falta de flexibilidad tecnol√≥gica: Dado que todos los componentes est√°n juntos, toda la aplicaci√≥n debe estar desarrollada con las mismas tecnolog√≠as, lo que limita la capacidad de utilizar diferentes herramientas o lenguajes para diferentes partes.
- **Despliegue m√°s complicado:** Cualquier cambio, por peque√±o que sea, requiere volver a desplegar toda la aplicaci√≥n, lo que puede aumentar el tiempo de inactividad y el riesgo de errores.
- **Mantenimiento dif√≠cil con el crecimiento:** A medida que la aplicaci√≥n crece en tama√±o y complejidad, se vuelve m√°s dif√≠cil mantener el c√≥digo, realizar actualizaciones y corregir errores sin afectar otras partes del sistema.
- **Dependencias fuertes entre componentes:** Los componentes dentro de un monolito tienden a tener dependencias estrechas, lo que dificulta la implementaci√≥n de nuevas caracter√≠sticas o cambios sin romper otras partes del sistema.

![image](https://github.com/user-attachments/assets/6b6f2494-427a-4f63-8beb-3409580a2e6c)

## ¬øCuando escoger qu√©?
La elecci√≥n entre una arquitectura monol√≠tica y una de microservicios depende de varios factores, como la escala del proyecto, la complejidad del sistema y el equipo de desarrollo. Aqu√≠ te doy un ejemplo de cu√°ndo elegir cada una y las razones detr√°s de esa decisi√≥n:
![image](https://github.com/user-attachments/assets/cc42ffc2-5e46-4f08-b610-7a5f426e27ed)

![image](https://github.com/user-attachments/assets/0a05d8a9-0f2d-4ddb-a7bf-96b57a2eb426)

### Combinaciones que llevan a monolito

1.- Peque√±a Escala + Simplicidad + Equipo Peque√±o + No Escalabilidad Independiente + No Resiliencia Alta + Latencia baja preocupaci√≥n.
(Sistema peque√±o, simple, sin necesidad de escalar ni alta resiliencia, con llamadas locales r√°pidas).

2.- Peque√±a Escala + Simplicidad + Equipo Peque√±o + No Escalabilidad Independiente + Resiliencia Alta + Latencia baja preocupaci√≥n.
(Sistema peque√±o y simple, pero con alta resiliencia, y latencia interna baja por la comunicaci√≥n local).

3.- Peque√±a Escala + Simplicidad + Equipo Grande + No Escalabilidad Independiente + No Resiliencia Alta + Latencia baja preocupaci√≥n.
(El equipo es grande, pero el sistema sigue siendo peque√±o y simple, con baja latencia debido a la ausencia de comunicaci√≥n distribuida).

4.- Peque√±a Escala + Complejidad Alta + Equipo Peque√±o + No Escalabilidad Independiente + No Resiliencia Alta + Latencia baja preocupaci√≥n.
(Aunque el sistema es complejo, el equipo es peque√±o, no requiere escalabilidad ni resiliencia, y mantiene baja latencia local).

**ESCENARIO DE MICROSERVICIOS**
![image](https://github.com/user-attachments/assets/4a5becc7-9243-495c-8d96-bb4fca050f47)

![image](https://github.com/user-attachments/assets/a801de09-883b-4d1c-961f-25ed974914c2)

### Combinaciones que llevan a microservicios
1.- Gran Escala + Complejidad Alta + Equipo Grande + Escalabilidad Independiente + Resiliencia Alta 
(Sistema grande y complejo, con equipos grandes, donde es cr√≠tico escalar partes del sistema y se requiere alta resiliencia).

2.- Gran Escala + Complejidad Alta + Equipo Grande + Escalabilidad Independiente + No Resiliencia Alta.
(El sistema es grande y complejo, se necesita escalabilidad independiente, pero la resiliencia no es cr√≠tica).

3.- Gran Escala + Complejidad Alta + Equipo Peque√±o + Escalabilidad Independiente + Resiliencia Alta .
(El equipo es peque√±o, pero el sistema es grande y requiere escalabilidad, resiliencia.).

4.- Gran Escala + Complejidad Alta + Equipo Peque√±o + Escalabilidad Independiente + No Resiliencia Alta .
(El sistema es grande y requiere escalabilidad independiente, pero la resiliencia.).

5.- Gran Escala + Complejidad Alta + Equipo Grande + Escalabilidad Independiente + Resiliencia Alta
(Sistema grande y complejo, con necesidad de escalabilidad y resiliencia).


## ¬øQu√© es Kubernetes?

Kubernetes (abreviado como K8s) es una plataforma de c√≥digo abierto dise√±ada para automatizar el despliegue, la escalabilidad y la gesti√≥n de aplicaciones en contenedores. Los contenedores permiten empaquetar aplicaciones con todas sus dependencias, lo que facilita su portabilidad y ejecuci√≥n en diferentes entornos. Sin embargo, gestionar m√∫ltiples contenedores y garantizar que funcionen correctamente en grandes entornos distribuidos puede ser complejo.

Ah√≠ es donde entra Kubernetes: orquesta estos contenedores de manera que pueda asegurarse de que siempre est√©n disponibles, correctamente distribuidos en los recursos de hardware, y que se ajusten autom√°ticamente a la demanda. Kubernetes maneja tareas como balanceo de carga, escalado autom√°tico, recuperaci√≥n ante fallos y despliegues continuos, permitiendo a los equipos de desarrollo enfocarse en escribir c√≥digo sin preocuparse por la infraestructura subyacente.

### Caracter√≠sticas Clave de Kubernetes:

- **Orquestaci√≥n**: Gestiona la implementaci√≥n y la comunicaci√≥n entre contenedores.
- **Escalabilidad**: Escala autom√°ticamente los microservicios seg√∫n la carga.
- **Balanceo de Carga**: Distribuye el tr√°fico entre los diferentes contenedores.
- **Recuperaci√≥n ante Fallos**: Reinicia autom√°ticamente los contenedores fallidos y reemplaza los nodos defectuosos.

## KUBERNETES VS DOCKER SWAM
Al elegir una plataforma de orquestaci√≥n, se deben considerar aspectos como escalabilidad, facilidad de uso, complejidad, soporte de la comunidad y capacidades de integraci√≥n.

### An√°lisis de Alternativas

1. **Facilidad de Uso**
   - **Kubernetes**: Tiene una curva de aprendizaje m√°s empinada debido a su complejidad, pero permite una personalizaci√≥n detallada y potente.
   - **Docker Swarm**: Es m√°s f√°cil de aprender y usar, ideal para despliegues r√°pidos y sencillos.

2. **Escalabilidad**
   - **Kubernetes**: Dise√±ado para aplicaciones complejas y de gran escala. Es ideal para ambientes en la nube y soporta m√∫ltiples nodos y cargas de trabajo de alta disponibilidad.
   - **Docker Swarm**: Aunque es m√°s f√°cil de configurar, no escala tan eficientemente como Kubernetes en aplicaciones complejas o distribuidas a gran escala.

3. **Comunidad y Soporte**
   - **Kubernetes**: Respaldado por una comunidad vasta y activa, con una gran cantidad de recursos, foros y documentaci√≥n.
   - **Docker Swarm**: Aunque cuenta con una comunidad activa, es menos popular que Kubernetes, y su adopci√≥n ha disminuido en favor de este √∫ltimo.

4. **Flexibilidad y Personalizaci√≥n**
   - **Kubernetes**: Ofrece una mayor flexibilidad con opciones avanzadas de configuraci√≥n, integraciones, y manejo de redes. Permite adaptar cada aspecto del ciclo de vida de los contenedores.
   - **Docker Swarm**: Tiene menos opciones de personalizaci√≥n, pero eso lo hace m√°s simple y f√°cil de manejar para casos de uso menos complejos.

5. **Desempe√±o**
   - **Kubernetes**: Tiende a ser m√°s pesado debido a su complejidad y n√∫mero de componentes. Sin embargo, est√° optimizado para entornos a gran escala.
   - **Docker Swarm**: M√°s r√°pido y ligero en implementaciones peque√±as o medianas.

6. **Integraci√≥n y Ecosistema**
   - **Kubernetes**: Se integra f√°cilmente con proveedores de la nube, herramientas de monitoreo, almacenamiento y seguridad.
   - **Docker Swarm**: Se integra bien dentro del ecosistema Docker, pero ofrece menos soporte para herramientas externas y complementos de terceros.

### Conclusi√≥n
- **Kubernetes** es la mejor opci√≥n para proyectos grandes y complejos, donde la escalabilidad y la flexibilidad son cruciales. Es la elecci√≥n para organizaciones que buscan soluciones a largo plazo y alta disponibilidad.
- **Docker Swarm** es ideal para proyectos peque√±os o medianos que requieren una implementaci√≥n r√°pida y sencilla. Es perfecto para desarrolladores que ya utilizan Docker y necesitan una soluci√≥n de orquestaci√≥n sin complicaciones.

### Recomendaci√≥n
Si el objetivo es soportar aplicaciones a gran escala con alta disponibilidad, Kubernetes es la opci√≥n recomendada. Para proyectos que priorizan la simplicidad y un ciclo de desarrollo r√°pido, Docker Swarm puede ser m√°s adecuado.

### Diagrama de comparai√≥n Kubernetes vs Docker Swarm

```mermaid
graph TD;
    A[¬øNecesitas escalabilidad para aplicaciones complejas?] -->|S√≠| B[Kubernetes]
    A -->|No| C[Docker Swarm]

    B --> D[¬øEs importante la personalizaci√≥n avanzada?]
    C --> E[¬øBuscas facilidad de uso y simplicidad?]

    D -->|S√≠| F[Kubernetes]
    D -->|No| G[Kubernetes]

    E -->|S√≠| H[Docker Swarm]
    E -->|No| I[Kubernetes]

    G --> J[¬øRequieres integraci√≥n con m√∫ltiples herramientas y ecosistemas?]
    H --> K[¬øBuscas despliegue r√°pido y sencillo?]

    J -->|S√≠| L[Kubernetes]
    J -->|No| M[Docker Swarm]

    K -->|S√≠| N[Docker Swarm]
    K -->|No| O[Kubernetes]
```

## Comparaci√≥n entre EKS en AWS y Kubernetes Independiente

Kubernetes es una plataforma de c√≥digo abierto desarrollada por Google para la automatizaci√≥n del despliegue, escalado y operaci√≥n de contenedores de aplicaciones. Amazon Elastic Kubernetes Service (EKS) es un servicio gestionado por AWS que facilita el uso de Kubernetes en la nube.

### Decisi√≥n
Se identifican las siguientes diferencias clave entre EKS y Kubernetes independiente:

1. **Gesti√≥n y Operaciones**
   - **Kubernetes Independiente**: Requiere configuraci√≥n y gesti√≥n manual considerable. Todas las tareas, desde la configuraci√≥n del plano de control hasta la gesti√≥n de nodos, deben realizarse manualmente.
   - **EKS**: AWS gestiona el plano de control de Kubernetes, incluyendo actualizaciones, parches y escalabilidad, lo que reduce la carga operativa para los desarrolladores.

2. **Integraci√≥n con Servicios de AWS**
   - **Kubernetes Independiente**: La integraci√≥n con servicios de la nube debe hacerse manualmente, lo que puede no ser tan fluido.
   - **EKS**: Se integra naturalmente con servicios de AWS como Elastic Load Balancer (ELB), IAM y CloudWatch, facilitando su uso.

3. **Coste**
   - **Kubernetes Independiente**: Puede resultar menos costoso en t√©rminos de infraestructura, pero el coste total debe incluir el tiempo y recursos de gesti√≥n.
   - **EKS**: Implica una tarifa de gesti√≥n, pero reduce la carga operativa y ofrece integraci√≥n fluida con servicios de AWS.

4. **Escalabilidad y Disponibilidad**
   - **Kubernetes Independiente**: Puede tener limitaciones en escalabilidad y disponibilidad.
   - **EKS**: Aprovecha la infraestructura de AWS para ofrecer mejor escalabilidad y disponibilidad, permitiendo la creaci√≥n de m√∫ltiples Zonas de Disponibilidad.

### Datos interesantes sobre EKS
- Permite ejecutar un servicio de Kubernetes gestionado sin necesidad de instalar, operar y mantener el plano de control o nodos de Kubernetes.
- EKS ejecuta instancias del plano de control de Kubernetes en m√∫ltiples Zonas de Disponibilidad para garantizar alta disponibilidad.
- Detecta autom√°ticamente y reemplaza instancias del plano de control no saludables.
- Proporciona actualizaciones autom√°ticas de versiones y parches para las instancias del plano de control.

### Consecuencias
La elecci√≥n entre EKS y Kubernetes independiente depende de las necesidades del proyecto y los recursos disponibles:
- **Kubernetes Independiente**: Opci√≥n adecuada si se requiere mayor control y personalizaci√≥n o si se desea desplegar en m√∫ltiples proveedores de nube o en instalaciones locales.
- **EKS**: Mejor opci√≥n si se prefiere una soluci√≥n menos intensa operativamente con integraci√≥n fluida en AWS.

### Conclusi√≥n
Ambas opciones tienen el prop√≥sito de orquestar aplicaciones en contenedores, pero las diferencias en gesti√≥n, integraci√≥n, coste, escalabilidad y disponibilidad deben considerarse para guiar la elecci√≥n entre EKS y Kubernetes independiente.

# Diagrama de Decisi√≥n: EKS vs. Kubernetes Independiente

```mermaid
graph TD;
    A[¬øNecesitas gestionar el plano de control manualmente?] -->|S√≠| B[¬øRequieres mayor control y personalizaci√≥n?]
    A -->|No| C[¬øPrefieres una soluci√≥n gestionada?]
    
    B -->|S√≠| D[Selecciona Kubernetes Independiente]
    B -->|No| E[¬øEl coste operativo es una preocupaci√≥n?]

    C -->|S√≠| F[Selecciona EKS]
    C -->|No| G[¬øNecesitas integraci√≥n con servicios de AWS?]
    
    E -->|S√≠| H[Selecciona Kubernetes Independiente]
    E -->|No| I[Selecciona EKS]
    
    G -->|S√≠| J[Selecciona EKS]
    G -->|No| K[¬øRequiere tu proyecto alta disponibilidad?]

    K -->|S√≠| L[Selecciona EKS]
    K -->|No| M[Selecciona Kubernetes Independiente]
```

## Comparativa de Kubernetes Ingress: ALB vs. Nginx
En el entorno de Kubernetes, es esencial gestionar eficientemente el tr√°fico entrante hacia los servicios. Existen dos soluciones populares para este prop√≥sito: Kubernetes Ingress con AWS Application Load Balancer (ALB) y Kubernetes Ingress con Nginx. Cada una ofrece caracter√≠sticas distintas que pueden adaptarse a diferentes necesidades organizativas.

Elegir entre Kubernetes Ingress con ALB y Nginx se basa en los siguientes criterios:

### 1. AWS Application Load Balancer (ALB) Ingress
- **Prop√≥sito e Integraci√≥n**:
  - ALB se integra de manera estrecha con el ecosistema de AWS, ofreciendo una infraestructura de aplicaci√≥n cohesiva para cl√∫steres de Kubernetes alojados en AWS.

- **Balanceo de Carga en Capa 7**:
  - Permite enrutar el tr√°fico basado en criterios avanzados como rutas de URL, nombres de host y encabezados, ideal para escenarios complejos.

- **Caracter√≠sticas Avanzadas**:
  - Soporta AWS WAF (Web Application Firewall) y terminaci√≥n SSL/TLS, simplificando el manejo de conexiones seguras.

- **Limitaciones**:
  - Exclusivo para AWS, lo que lo hace menos adecuado para implementaciones multicloud o h√≠bridas.

### 2. Nginx Ingress Controller
- **Versatilidad y Compatibilidad Multinube**:
  - Nginx se puede desplegar en diversos entornos, incluyendo diferentes proveedores de nube y configuraciones on-premises, lo que lo convierte en una opci√≥n adecuada para infraestructuras complejas.

- **Flexibilidad de Enrutamiento**:
  - Ofrece opciones de enrutamiento flexibles, incluyendo hosting virtual basado en nombre y reescrituras de URL.

- **Control de Configuraci√≥n**:
  - Requiere m√°s configuraci√≥n manual, lo que puede ser una ventaja para usuarios avanzados, pero un desaf√≠o para quienes son menos experimentados.

- **Ventajas**:
  - No est√° vinculado a un proveedor espec√≠fico de nube, lo que facilita su uso en entornos multicloud e h√≠bridos.

### Consecuencias
- **Si se elige ALB**:
  - Se obtiene una integraci√≥n fluida con los servicios de AWS y caracter√≠sticas avanzadas de seguridad, aunque con la limitaci√≥n de estar atado a la infraestructura de AWS.

- **Si se elige Nginx**:
  - Se permite una mayor flexibilidad y personalizaci√≥n en el enrutamiento, adem√°s de la posibilidad de utilizarlo en m√∫ltiples nubes, aunque a expensas de una mayor complejidad en la configuraci√≥n.

### Conclusi√≥n
La decisi√≥n entre ALB y Nginx debe basarse en los requisitos espec√≠ficos de la organizaci√≥n. Para aplicaciones en AWS que requieren integraci√≥n directa con servicios de AWS, ALB es la mejor opci√≥n. Sin embargo, para entornos m√°s vers√°tiles que requieren personalizaci√≥n y compatibilidad multicloud, Nginx es preferible.

### Diagrama de Decisi√≥n: ALB vs. Nginx Ingress

```mermaid
graph TD;
    A[¬øEst√°s en el ecosistema de AWS?] -->|S√≠| B[¬øNecesitas caracter√≠sticas avanzadas de seguridad?]
    A -->|No| C[¬øNecesitas compatibilidad multicloud?]
    
    B -->|S√≠| D[¬øRequiere tu aplicaci√≥n balanceo de carga en Capa 7?]
    B -->|No| E[¬øRequiere integraci√≥n con servicios de AWS?]
    
    C -->|S√≠| F[Selecciona Nginx]
    C -->|No| G[¬øRequiere tu aplicaci√≥n un enrutamiento complejo?]
    
    D -->|S√≠| H[Selecciona ALB]
    D -->|No| I[Selecciona ALB]

    E -->|S√≠| J[Selecciona ALB]
    E -->|No| K[¬øTu equipo tiene experiencia con Nginx?]

    G -->|S√≠| L[Selecciona Nginx]
    G -->|No| M[Selecciona Nginx]
    K -->|S√≠| N[Selecciona Nginx]
    K -->|No| O[Selecciona ALB]
```


# Demo - Despliegue de una arquitectura de microservicios con kubernetes en AWS EKS 

La demo se basa en desplegar tres servicios que se comunian entre si usando RabbitMQ (para el cual usamos Amazon MQ en la arquitectura). Asimismo, los tres utilizan una base de datos no relacional, mongoDb para almacenar informaci√≥n. Para su despleigue se utiliza AWS EKS, el cual se muestra mejor en la arquitectura presentada.

## Arquitectura Cloud 

![image](https://github.com/user-attachments/assets/53a6362f-0657-4e48-bb3d-787f63e22f3d)


Este diagrama representa una arquitectura en AWS que utiliza Amazon EKS, Amazon MQ, balanceo de carga el√°stica (ELB), y un VPC conectado mediante peering con MongoDB para los servicios de base de datos. Los componentes clave son:

- **Amazon EKS**: Un servicio de Kubernetes alojado en AWS para gestionar aplicaciones contenedorizadas.
- **Amazon MQ**: Un servicio de mensajer√≠a integrado dentro del VPC para manejar la comunicaci√≥n entre servicios.
- **Elastic Load Balancing (ELB)**: Distribuye el tr√°fico entrante a trav√©s de varios nodos dentro del cl√∫ster.
- **Nodos**: Ubicados en subredes privadas distribuidas en dos zonas de disponibilidad para garantizar alta disponibilidad.
- **Peering de VPC**: Conecta el VPC principal con un segundo VPC donde est√° alojado MongoDB, permitiendo una comunicaci√≥n segura.

## Arquitectura de Servicios Kubernetes

![image](https://github.com/user-attachments/assets/dc1819c3-f431-4baf-8da0-ee5ddeb2dc2e)

Este diagrama muestra una arquitectura t√≠pica de servicios en Kubernetes utilizando un balanceador de carga para gestionar el tr√°fico entrante hacia diferentes microservicios. Los elementos clave incluyen:

- **Load Balancer HTTPS**: Dirige el tr√°fico externo hacia el cl√∫ster. --> Usamos el AWS ALB
- **Ingress (ing)**: Administra el acceso a los servicios, recibiendo tr√°fico desde el balanceador de carga y enrut√°ndolo internamente.  --> Usamos el AWS ALB Ingress
- **Servicios (svc)**: Conectan el tr√°fico a los pods espec√≠ficos que ejecutan diferentes servicios.
- **Pods**: Ejecutando distintos microservicios como `orders`, `billing` y `auth`, todos dentro del mismo namespace.

Esta configuraci√≥n resalta el uso de un balanceador de carga, un ingress y servicios para escalar los microservicios de manera eficiente dentro de un cl√∫ster de Kubernetes.

## Herramienta utlizada para el desliegue: HELM

**Helm** es una herramienta de gesti√≥n de paquetes para Kubernetes, que simplifica la instalaci√≥n, actualizaci√≥n y gesti√≥n de aplicaciones dentro de un cl√∫ster.

### Conceptos Clave

- **Charts**: Conjuntos de archivos YAML que definen los recursos necesarios para ejecutar una aplicaci√≥n en Kubernetes.
    Un chart puede incluir archivos como:
  
    - **Deployment**: Define c√≥mo se ejecutar√°n los contenedores de la aplicaci√≥n.
    - **Services**: Configura c√≥mo se exponen los contenedores.
    - **ConfigMaps/Secrets**: Almacenan configuraciones sensibles o no sensibles.
    - **Ingress**: Define c√≥mo el tr√°fico externo accede a la aplicaci√≥n
    - **Release**: Una instancia instalada de un chart en Kubernetes. Cada actualizaci√≥n genera una nueva release.
    - **Plantillas**: Permiten parametrizar configuraciones mediante variables, facilitando la personalizaci√≥n del despliegue.

### Beneficios

- **Simplicidad**: Instalaci√≥n de aplicaciones con un solo comando.
- **Consistencia**: Despliegue coherente en entornos de desarrollo, pruebas y producci√≥n.
- **Reusabilidad**: Uso de charts compartidos y reutilizables.
- **Gesti√≥n de Versiones**: Facilita actualizaciones y retrocesos (rollback) de aplicaciones.


## PASO A PASO 

1.- Crear workspace para crear nuestro microservicios en Nest.js

![image](https://github.com/user-attachments/assets/f992ca36-2d8b-4d6e-b340-d46e943d4ef9)

2.- Vamos creando nuestra app order, billing y auth con el mismo comando 
![image](https://github.com/user-attachments/assets/996afc94-067b-492f-bbdd-f3f7865e5963)

3.- Creamos nuestra libreria en comun con
**nest g library commo**
![image](https://github.com/user-attachments/assets/14e10c18-f47d-4389-a815-8d01cc45a46d)

4.- Instalamos mongoose para manejo de mongoDb, y las dem√°s dependencias necesarias para crear configuraciones necesarias como JWT, RabbitMQ

![image](https://github.com/user-attachments/assets/0c4bfaa2-dcf0-4745-8032-ca2eea8415de)

5.- Luego de establecer una comunicacion entre los microservicios que escuchan a RabbitMQ creamos las imagenes de nustros servicios
![image](https://github.com/user-attachments/assets/5aefbd6f-cef8-4876-af59-1cef49bfbe22)

![image](https://github.com/user-attachments/assets/52f1d58b-761f-4de5-87a1-71179f56aacd)

6.- Se sube nuestras imaganes a Docker Hub para usarlas despues 
![image](https://github.com/user-attachments/assets/eb2404f9-2d3e-4e60-9683-c4626707451e)


7.- Ahora creamos los recursos en la nube, RabbitMQ y MongoDB
![image](https://github.com/user-attachments/assets/95ab7a9a-c20a-4d1c-b541-c6b6a75980ce)

8.- Creamos un cluster y una bd en MongoDb Atlas

![image](https://github.com/user-attachments/assets/d2ccf55c-4e9e-49e4-8b0e-9b831be25584)

9.- Creamos una carpeta helm en nuestro workspace e instalamos helm, para ello seguir la siguiente documentaci√≥n
  - https://helm.sh/docs/intro/install/

10.- Luego ejecutamos el comando helm install ordering-app

![image](https://github.com/user-attachments/assets/c1f46c1b-8d81-4163-8c4f-fd6af941aa98)

11.- Configurar los deployment, service  e ingress
![image](https://github.com/user-attachments/assets/efa21ef7-5909-410e-9c26-71129b727fd2)
![image](https://github.com/user-attachments/assets/288aee3b-d9c6-48ff-a516-6f08bc503705)
![image](https://github.com/user-attachments/assets/9079f683-2909-4b5d-a87c-e06f63c6d620)


12.- Instalar AWS CLI y Eksctl
- https://docs.aws.amazon.com/eks/latest/userguide/what-is-eks.html
- https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html

13.- AL tener ambos configurados con eksctl se crea el cluster : eksctl create cluster ordering-app

14.- Se configura el ALB para que mas adelante use nuestro ingress , para ello se sigue la siguiente doumentaci√≥n

- https://kubernetes-sigs.github.io/aws-load-balancer-controller/v2.4/

15.- Finalmente se despliega nuestro aplicativo usando helm install ordering-app

16.- Luego de ello tendremos nuestro app  y cada microservicio orriendo en eks





**DEMO VIDEO:** https://streamyard.com/r79dgvp86fgg


**REPOSITORIO:** https://github.com/AndreaLlerena2003/demo-ArquiDeSoftware-LlerenaAndrea



# Patr√≥n Cloud - Saga

## Desarrollo del Patr√≥n:

- **Problema**: En un sistema distribuido, realizar una transacci√≥n que involucra m√∫ltiples servicios puede ser riesgoso, ya que cualquier falla en uno de los servicios puede dejar la transacci√≥n en un estado inconsistente. Un sistema necesita garantizar que, incluso si ocurre un error, pueda deshacer las acciones previas o completar la transacci√≥n de forma consistente.

- **Soluci√≥n**: El **patr√≥n Saga** divide una transacci√≥n en una serie de pasos independientes, donde cada paso tiene una acci√≥n compensatoria asociada. Si alg√∫n paso falla, las acciones previas se revierten mediante estas acciones compensatorias, lo que asegura que el sistema vuelva a un estado consistente.
  
## Conceptos Fundamentales:
- **Transacciones Distribuidas:** En un sistema distribuido, las operaciones pueden involucrar m√∫ltiples microservicios que pueden tener sus propias bases de datos. Esto dificulta la implementaci√≥n de transacciones at√≥micas.
- **Compensaci√≥n:** Cuando una operaci√≥n dentro de una saga falla, es necesario revertir (o compensar) las operaciones que ya se han completado. Esto se logra mediante operaciones compensatorias que deshacen los efectos de las operaciones previas.
- **Orquestaci√≥n vs. Coreograf√≠a:**
    - **Orquestaci√≥n:** Un componente central (el orquestador) dirige el flujo de la saga, enviando mensajes a los participantes y coordinando las acciones.
    - **Coreograf√≠a:** Cada servicio participante se comunica entre s√≠ a trav√©s de eventos, sin un controlador central. Cada servicio conoce su parte de la saga y responde a eventos de otros servicios.

| **Aspecto**                | **Orquestaci√≥n**                                                | **Coreograf√≠a**                                                |
|----------------------------|---------------------------------------------------------------|--------------------------------------------------------------|
| **Definici√≥n**             | Un componente central (orquestador) dirige el flujo de la saga. | Los servicios participantes se comunican entre s√≠ mediante eventos. |
| **Control**                | Control centralizado, donde el orquestador toma decisiones.   | Control distribuido, cada servicio gestiona su propia l√≥gica. |
| **Complejidad**            | Puede ser m√°s simple de entender debido a la centralizaci√≥n.  | Puede volverse complejo a medida que aumenta el n√∫mero de servicios. |
| **Escalabilidad**          | Escalable, pero puede convertirse en un punto √∫nico de fallo. | Escalable y resiliente, sin un punto √∫nico de fallo.        |
| **Manejo de Errores**      | El orquestador puede implementar estrategias de manejo de errores de manera centralizada. | Requiere que cada servicio implemente su propio manejo de errores. |
| **Visibilidad**            | Mayor visibilidad del flujo de trabajo y estado general.       | Puede ser dif√≠cil de rastrear y depurar debido a la falta de control central. |
| **Desarrollo**             | Permite un desarrollo m√°s lineal y controlado.                | Favorece la autonom√≠a de los equipos, permitiendo iteraciones independientes. |
| **Flexibilidad**           | Menos flexible, ya que cualquier cambio en el flujo requiere modificaciones en el orquestador. | M√°s flexible, permite que los servicios se adapten sin afectar a otros. |
| **Implementaci√≥n**         | Puede requerir herramientas y tecnolog√≠as adicionales para el orquestador. | Requiere un dise√±o s√≥lido de eventos y una infraestructura que soporte la comunicaci√≥n entre servicios. |
| **Ejemplos de Uso**        | Ideal para flujos de trabajo complejos con pasos claramente definidos. | Adecuado para sistemas altamente distribuidos y din√°micos donde la autonom√≠a de los servicios es clave. |


## Estructura del Saga:
- **Pasos de la Saga:** Una saga consta de una secuencia de pasos donde cada paso representa una operaci√≥n realizada por un microservicio. Cada operaci√≥n debe ser capaz de ejecutarse independientemente y tener una operaci√≥n compensatoria.
- **Gestor de Sagas:** Un gestor (o coordinador) es responsable de gestionar el estado de la saga, asegur√°ndose de que todas las operaciones se realicen correctamente y, en caso de fallo, se ejecuten las operaciones compensatorias.

## Comparativa de Saga Manual vs Saga con Servicios Cloud

| **Aspecto**                | **Saga Manual**                                                 | **Azure Durable Functions**                                   |
|----------------------------|----------------------------------------------------------------|--------------------------------------------------------------|
| **Implementaci√≥n**         | Requiere dise√±o y codificaci√≥n manual del flujo de trabajo.   | Proporciona una manera estructurada de definir flujos de trabajo con menos esfuerzo manual. |
| **Gesti√≥n del Estado**     | Necesita mantener el estado de la saga manualmente (por ejemplo, en base de datos). | Maneja autom√°ticamente el estado de las funciones, permitiendo que se suspendan y reanuden sin perder datos. |
| **Escalabilidad**          | Puede ser dif√≠cil de escalar, ya que depende del dise√±o de la aplicaci√≥n y la infraestructura. | Altamente escalable, dise√±ado para manejar cargas variables sin necesidad de cambios significativos en el c√≥digo. |
| **Manejo de Errores**      | Se requiere l√≥gica de manejo de errores y compensaci√≥n manual. | Integraci√≥n de manejo de errores y compensaci√≥n a trav√©s de patrones predefinidos. |
| **Despliegue**             | Necesita gestionar la infraestructura y el despliegue manualmente. | Despliegue m√°s sencillo a trav√©s del portal de Azure y la CLI, con integraci√≥n continua posible. |
| **Costos**                 | Costos fijos asociados a la infraestructura y mantenimiento.   | Modelo de pago por uso, basado en la ejecuci√≥n de funciones, que puede ser m√°s econ√≥mico en funci√≥n de la carga. |
| **Flexibilidad**           | Permite total personalizaci√≥n de la l√≥gica de la saga.        | Limitado por la estructura de Durable Functions, aunque ofrece suficiente flexibilidad para la mayor√≠a de los casos de uso. |
| **Interoperabilidad**      | Necesita implementar integraciones con otros servicios manualmente. | Soporta integraci√≥n f√°cil con otros servicios de Azure y APIs externas. |
| **Desarrollo y Mantenimiento** | Mayor carga en el equipo de desarrollo para crear y mantener el flujo de trabajo. | Facilita el desarrollo y el mantenimiento con herramientas y plantillas de Azure. |
| **Complejidad del C√≥digo** | Puede resultar en un c√≥digo m√°s complejo y dif√≠cil de seguir a medida que crece el n√∫mero de pasos. | Estructura m√°s clara y f√°cil de seguir debido a la naturaleza de las funciones y los orquestadores. |
| **Pruebas y Debugging**    | Las pruebas pueden ser complicadas debido a la naturaleza del flujo de trabajo. | Mejores capacidades de prueba y depuraci√≥n gracias a la naturaleza modular de las funciones. |


## Casos de Aplicaci√≥n:

1. **Procesos de reserva de vuelos y hoteles**:
   - Al reservar un paquete de viaje que incluye vuelo y hotel, el sistema debe garantizar que si la reserva del vuelo falla, la reserva del hotel tambi√©n se deshaga. El patr√≥n Saga asegura que ambas operaciones se realicen exitosamente o se reviertan en caso de error.

2. **Pedidos en e-commerce**:
   - En sistemas de comercio electr√≥nico, al procesar una orden que implica verificar el inventario, cobrar al cliente y enviar el pedido, si alguno de los pasos falla (por ejemplo, el inventario no est√° disponible), las acciones previas deben revertirse, como cancelar el cargo al cliente.

3. **Transferencias bancarias**:
   - Las transferencias bancarias entre cuentas en diferentes bancos pueden usar Saga. Si la transferencia en uno de los bancos falla, el sistema puede compensar la operaci√≥n deshaciendo la transacci√≥n en el banco que ya realiz√≥ el cargo.

## Aplicaci√≥n en Trabajo de Grupo:

- **Problema**: Se est√° desarrollando un sistema de reservas y compras en l√≠nea que involucra la reserva de m√∫ltiples recursos, como productos, inventario, y el procesamiento de pagos. Si alg√∫n paso falla, el sistema debe poder compensar las acciones anteriores.
  
- **Soluci√≥n**: Implementar el patr√≥n Saga para asegurar que, si una reserva de inventario o el procesamiento del pago falla, se deshagan las acciones previas (como la reserva del producto en el sistema o el cargo a la tarjeta de cr√©dito). Esto garantizar√° que el sistema mantenga la consistencia y que no se afecte negativamente la experiencia del cliente.

  
## Desarrollo de C√≥digo y Demo:
![image](https://github.com/user-attachments/assets/fada59a2-e1e4-4fe4-82b4-54bf3d4ca879)

![image](https://github.com/user-attachments/assets/97725238-c8e3-45f9-adc9-1ce4ae7b020c)

En las imagenes se muestra el flujo implementado, se busca hacer la gestion de reservas en un SPA (para le demo solo se trabaja con un solo salon de belleza), se usan tres microservicios, availability-service, payment-service y reservation-service. Los tres tienen su propia base de datos en mongo definida en el archivo de docker-compose.yaml de la demo. El patron SAGA implementado es del tipo **Orquestaci√≥n**, ya que el servicio reservation-service, es el componente central que dirije la saga. 

### Clases y Componentes

#### `CreateAppointmentSaga`

- **Responsabilidad**: Controlar la ejecuci√≥n de una serie de pasos para la creaci√≥n de citas, manejar errores y realizar rollbacks si es necesario.

#### Propiedades

- `steps`: Un array que contiene los pasos a ejecutar en la saga.
- `successfulSteps`: Un array que mantiene un registro de los pasos que se han completado con √©xito.

#### Constructor

- **Par√°metros**:
  - `placeAppointmentStep`: Paso para colocar la cita.
  - `checkAvailabilityStep`: Paso para verificar la disponibilidad.
  - `authorizePaymentStep`: Paso para autorizar el pago.
  - `confirmAppointmentStep`: Paso para confirmar la cita.
  - `updateAvailabilityStep`: Paso para actualizar la disponibilidad.

#### M√©todos

- `execute`: Ejecuta cada paso de la saga. Si un paso falla, realiza el rollback de todos los pasos exitosos hasta el momento.
  - **Par√°metros**:
    - `appointment`: La cita que se est√° creando.

- `rollbackSuccessfulSteps`: Revierte los pasos que se completaron con √©xito en caso de que ocurra un error en un paso posterior.
  - **Par√°metros**:
    - `appointment`: La cita que se est√° procesando.

#### Estructura de los STEPS
La clase `Step` es una clase abstracta que define la estructura b√°sica para cada paso en la saga. La cual es extendida por los steps espec√≠ficos mencionados. Estas son sus propiedades: 

  - `name`: Una cadena que representa el nombre del paso. Este nombre se utiliza para registrar informaci√≥n en los logs y facilitar la identificaci√≥n de cada paso durante la ejecuci√≥n de la saga.
  - `invoke(params: T): Promise<R>`: M√©todo abstracto que es implementado por las clases derivadas. Este m√©todo se encarga de ejecutar la l√≥gica del paso y devolver un resultado encapsulado en una promesa.
  - `withCompenstation(params: T): Promise<R>`: M√©todo abstracto que es implementado por las clases derivadas. Este m√©todo se utiliza para realizar la compensaci√≥n en caso de que el paso anterior falle o deba ser repetido. Es esencial para manejar errores y garantizar que el estado del sistema se mantenga consistente

Un dato importante es que por cada invoke, hay un evento en el respectivo servicio, por ejemplo, para el servicio payment, se tiene el evento 'payment.payment.authorize' , que se envia mediante el invoke, pero si sucede un tipo de error, se envia el evento 'payment.payment.refund', mediante el m√©todo withCompenstation.

## Flujo de Ejecuci√≥n

1. Se invoca el m√©todo `execute` con un objeto `Appointment`.
2. Se recorren los pasos en el orden definido en el constructor.
3. Cada paso se ejecuta y, si se completa correctamente, se a√±ade a la lista de pasos exitosos.
4. Si un paso falla, se llama al m√©todo de rollback, que revertir√° todos los pasos exitosos.
5. Se imprime un mensaje indicando si la creaci√≥n de la cita fue exitosa o si hubo un error.

## Prueba

1. Al ejecutar el post resepectivo para realizar una reserva podemos ver como se ejecuta los siguientes pasos
   ![image](https://github.com/user-attachments/assets/3c7e243f-b244-4231-a98c-6764605cb207)
2. Luego de ejeutarlo vemos como en el reservation service se ejecuta los pasos del patr√≥n saga
   ![image](https://github.com/user-attachments/assets/cf594d93-20b8-4a44-844d-26ef42168db1)
3. Y vemos como se llama los respectivos eventos a sus respectivos microservicios
   ![image](https://github.com/user-attachments/assets/8a0eac60-7701-4c88-9170-fbbccbf8c5d5)
   ![image](https://github.com/user-attachments/assets/dc744001-e323-4bb3-96a5-991386544fed)

5. Asimimismo en la UI de Kafka podemos ver los eventos enviados con su respectivo reply
   ![image](https://github.com/user-attachments/assets/6be30932-799c-454c-aa99-db903bab131e)
   ![image](https://github.com/user-attachments/assets/2c24c113-4077-47c8-bb03-41e180ab9f8a)
   ![image](https://github.com/user-attachments/assets/dbf3920a-321d-44a5-8963-17454b08823c)
   ![image](https://github.com/user-attachments/assets/79b72156-2551-4457-a1ec-d0d793789d7a)
   ![image](https://github.com/user-attachments/assets/a1fdf862-1fa3-4eee-8b72-8121e918cd02)
   ![image](https://github.com/user-attachments/assets/75c0bec7-6fc7-4f4c-b794-24a29c1b0174)

6. Finalmente vemos los resultados finales en la base de datos

    6.1. Resultado en BD Appointment -  Appointment collection
   ![image](https://github.com/user-attachments/assets/259ba92e-d664-43fa-a15b-ca2f5010ef4e)
    6.2. Resultado en BD Payment -  Payment collection
   ![image](https://github.com/user-attachments/assets/7c87cc5c-376c-4476-9d8d-4065089cc328)
    6.3. Resultado en BD Availability - Availability collection
   ![image](https://github.com/user-attachments/assets/4cd73ba0-1c23-44da-95d0-c7b9212d16f3)




## Link de Github
- https://github.com/AndreaLlerena2003/DEMO-SAGA-PATTERN-ANDREA_LLERENA

## Link de Apoyo
- https://learn.microsoft.com/en-us/azure/architecture/reference-architectures/saga/saga
- https://www.youtube.com/watch?v=AqMViipU284&ab_channel=Devoxx
   

# MLOps con MlFlow

## Introducci√≥n
MLOps (Machine Learning Operations) es un conjunto de pr√°cticas y herramientas que unifican el desarrollo de modelos de aprendizaje autom√°tico (machine learning) y su implementaci√≥n en producci√≥n. Su prop√≥sito es facilitar la colaboraci√≥n entre equipos de Data Science, desarrollo de software y operaciones, optimizando la entrega continua y la supervisi√≥n de modelos de machine learning a gran escala. MLOps se puede considerar una extensi√≥n de las pr√°cticas de DevOps aplicadas al √°mbito de la inteligencia artificial.

## Marco Te√≥rico de MLOps

MLOps emerge como una respuesta a los desaf√≠os de integrar y mantener modelos de machine learning en entornos productivos. Aunque el desarrollo de modelos de machine learning sigue el ciclo de vida cl√°sico de cualquier software, tiene caracter√≠sticas propias debido a la naturaleza din√°mica de los datos, la complejidad de los modelos y la necesidad de actualizaci√≥n constante.

### Componentes de MLOps

- **Automatizaci√≥n y pipeline de datos:** MLOps promueve la automatizaci√≥n de los flujos de trabajo, desde la recopilaci√≥n de datos hasta la implementaci√≥n de modelos. Esto incluye la creaci√≥n de pipelines de datos que automatizan la limpieza, transformaci√≥n y carga de datos para ser utilizados en el entrenamiento de modelos.

- **Gesti√≥n de modelos:** A medida que se entrenan m√∫ltiples modelos y versiones, MLOps se encarga de versionar, almacenar y gestionar estos modelos para asegurar que siempre se utilice la versi√≥n adecuada en producci√≥n.

- **Monitoreo y trazabilidad:** El monitoreo de los modelos es esencial para detectar desviaciones en su rendimiento o en los datos, lo que permite realizar ajustes o reentrenamientos. Las herramientas de trazabilidad aseguran que se pueda reproducir cualquier experimento o despliegue, lo cual es crucial para la auditor√≠a y el cumplimiento normativo.

- **Colaboraci√≥n entre equipos:** MLOps facilita la colaboraci√≥n entre los equipos de Data Science, ingenieros de datos, desarrolladores de software y operaciones de TI. Esto se logra mediante la integraci√≥n de herramientas y pr√°cticas que permiten una comunicaci√≥n fluida y la automatizaci√≥n de tareas repetitivas.

### Ciclo de Vida de MLOps

1. **Adquisici√≥n de datos:** Los datos son la base del modelo. En esta etapa, se recopilan, almacenan y procesan datos para que puedan ser utilizados en el entrenamiento.
   
2. **Preprocesamiento y limpieza de datos:** Los datos crudos suelen estar desordenados, incompletos o mal formateados. El preprocesamiento y la limpieza de datos incluyen la normalizaci√≥n, la transformaci√≥n de valores, el tratamiento de valores nulos, y la selecci√≥n de caracter√≠sticas relevantes.

3. **Entrenamiento y validaci√≥n de modelos:** En esta fase, se utilizan t√©cnicas de machine learning para crear un modelo predictivo. El proceso incluye la selecci√≥n de algoritmos, la validaci√≥n cruzada y la optimizaci√≥n de hiperpar√°metros.

4. **Despliegue y monitorizaci√≥n:** Una vez entrenado el modelo, es desplegado en un entorno de producci√≥n. En producci√≥n, el modelo hace inferencias sobre nuevos datos. Es importante monitorear el modelo continuamente para asegurar su rendimiento. Los indicadores clave incluyen el *drift* de datos, el *drift* del modelo y el rendimiento en tiempo real.

5. **Mantenimiento y actualizaci√≥n:** Los modelos pueden volverse obsoletos con el tiempo debido a cambios en los datos o el entorno. Los modelos deben actualizarse o reentrenarse peri√≥dicamente para mantener su relevancia y precisi√≥n.

### Herramientas y Tecnolog√≠as en MLOps

- **Automatizaci√≥n de pipelines:** Herramientas como **Kubeflow**, **Airflow**, **MLFlow** o **TensorFlow Extended (TFX)** son utilizadas para automatizar los pipelines de datos y modelos, desde la ingesti√≥n de datos hasta la implementaci√≥n.
  
- **Control de versiones de modelos y datos:** Herramientas como **DVC (Data Version Control)** o **MLFlow** permiten versionar tanto los datos como los modelos, asegurando que se pueda rastrear y reproducir cualquier experimento.

- **Infraestructura como c√≥digo (IaC):** Para gestionar la infraestructura en la que se ejecutan los modelos, MLOps hace uso de herramientas como **Terraform** y **Kubernetes**, lo que facilita la creaci√≥n de entornos de producci√≥n escalables y reproducibles.

- **Contenerizaci√≥n y orquestaci√≥n:** El uso de **Docker** para contenerizar aplicaciones y **Kubernetes** para su orquestaci√≥n son esenciales para la escalabilidad de los modelos en producci√≥n.

- **Monitoreo de modelos:** Herramientas como **Prometheus**, **Grafana**, **ELK stack** y **Seldon** permiten monitorear el rendimiento del modelo en producci√≥n, detectando cualquier anomal√≠a o desviaci√≥n en su rendimiento.

###  Desaf√≠os de MLOps

- **Escalabilidad:** A medida que los modelos crecen en complejidad, la infraestructura y los pipelines deben ser capaces de escalar sin comprometer el rendimiento. Esto puede ser un reto, especialmente cuando se procesan grandes vol√∫menes de datos o se realizan inferencias en tiempo real.

- **Gesti√≥n del ciclo de vida del modelo:** Los modelos de machine learning no son est√°ticos y pueden necesitar reentrenamiento frecuente, lo que puede llevar a la complejidad en la gesti√≥n de diferentes versiones de modelos, su implementaci√≥n y seguimiento.

- **Desviaci√≥n de datos (Data Drift):** Los modelos pueden volverse obsoletos si los datos en producci√≥n cambian. Detectar y adaptarse a estos cambios en los datos es un desaf√≠o clave de MLOps.

- **Colaboraci√≥n interequipos:** MLOps implica la interacci√≥n entre varios equipos, como los de Data Science, desarrollo de software e infraestructuras. La falta de comunicaci√≥n o la integraci√≥n de herramientas puede causar cuellos de botella en los procesos.

###  Impacto de MLOps en las Empresas
La adopci√≥n de MLOps permite a las empresas mejorar la eficiencia en el desarrollo y la implementaci√≥n de modelos de machine learning. La automatizaci√≥n de procesos reduce el tiempo de desarrollo y permite iteraciones m√°s r√°pidas, lo que se traduce en modelos m√°s precisos y eficaces. Adem√°s, la integraci√≥n continua de modelos con procesos de despliegue y monitorizaci√≥n constante contribuye a un ciclo de vida m√°s √°gil y adaptable a cambios.


## ADRs: Comparaci√≥n de Herramientas de MLOps - MLflow vs. Amazon SageMaker vs. Azure Machine Learning vs. Google AI Platform

### Contexto

Las herramientas de MLOps deben ofrecer capacidades de experimentaci√≥n, despliegue, monitorizaci√≥n y gesti√≥n de modelos en producci√≥n. Evaluamos aqu√≠ las herramientas **MLflow**, **Amazon SageMaker**, **Azure Machine Learning**, y **Google AI Platform** para ayudar en la selecci√≥n de la herramienta que mejor se ajuste a un entorno de producci√≥n.

---

### Decisi√≥n

Comparar las herramientas MLOps y destacar las fortalezas de cada una en funci√≥n de distintos criterios clave: funcionalidad, flexibilidad, facilidad de uso, integraci√≥n, costo, y escalabilidad.

| Criterio                       | MLflow                          | Amazon SageMaker                | Azure Machine Learning          | Google AI Platform              |
|--------------------------------|---------------------------------|---------------------------------|---------------------------------|---------------------------------|
| **Prop√≥sito**                  | Gesti√≥n de experimentos, implementaci√≥n, model tracking | Plataforma integral de ML gestionada por AWS | Plataforma completa de MLOps y DevOps en la nube | Soluci√≥n gestionada para entrenar, servir y monitorizar modelos en la nube de Google |
| **Gesti√≥n de Experimentos**    | ‚úîÔ∏è F√°cil, con versiones de experimentos y modelos | ‚úîÔ∏è Completo, con versiones autom√°ticas y tracking detallado | ‚úîÔ∏è Flexible, con dashboards personalizables | ‚úîÔ∏è Compatible con TensorBoard, f√°cil integraci√≥n con Google Colab |
| **Gesti√≥n de Modelos**         | ‚úîÔ∏è Sencilla, con seguimiento de artefactos y m√©tricas | ‚úîÔ∏è Completa, gesti√≥n automatizada de versiones | ‚úîÔ∏è Soporte para m√∫ltiples modelos y versiones | ‚úîÔ∏è Integrado con AI Hub y autoML para modelo-as-a-service |
| **Entrenamiento Escalable**    | üö´ Limitado a frameworks propios o integraci√≥n personalizada | ‚úîÔ∏è Servicios de entrenamiento distribuidos en AWS | ‚úîÔ∏è Jobs escalables, compatible con Kubernetes | ‚úîÔ∏è Escalable con Google Kubernetes Engine (GKE) |
| **Despliegue de Modelos**      | ‚úîÔ∏è Dockerizado o en entornos de prueba | ‚úîÔ∏è Completamente gestionado en AWS Lambda o endpoints | ‚úîÔ∏è Servicios gestionados y escalables con ACI o AKS | ‚úîÔ∏è Despliegue gestionado en GCP con autoescalado |
| **Integraci√≥n con Ecosistema** | ‚úÖ Compatible con cualquier nube, frameworks open-source | üîÑ Integrado profundamente con AWS, IAM, S3 | üîÑ Optimizado para ecosistema de Azure, DevOps y SQL | üîÑ Integraci√≥n con servicios de GCP (BigQuery, Dataflow) |
| **Facilidad de Uso**           | üëç Sencillo para peque√±as implementaciones | üëç Intuitivo para usuarios de AWS, m√∫ltiples opciones GUI | üëç Interfaz amigable y gu√≠as detalladas en Azure Portal | üëç Familiar para usuarios de GCP, gran compatibilidad con Google Colab |
| **Costo**                      | üíµ Bajo, gratuito y open-source; costos solo de infraestructura | üí∞ Costo en funci√≥n del uso de servicios AWS | üí∞ Pago por uso de recursos en Azure | üí∞ Escalable con pago por uso en Google Cloud Platform |
| **Escalabilidad**              | üö´ Limitada; depende de integraci√≥n personalizada | ‚úîÔ∏è Alto, optimizado para servicios AWS | ‚úîÔ∏è Alto, optimizado para entornos de Azure y Kubernetes | ‚úîÔ∏è Alto, escalable autom√°ticamente con GKE |

## Pros y Contras

#### MLflow

- **Pros:** 
  - Open-source, altamente personalizable.
  - Ideal para proyectos donde la flexibilidad es esencial y se prefiere una soluci√≥n agn√≥stica de nube.
  - Soporta m√∫ltiples frameworks de machine learning y tiene una comunidad activa.

- **Contras:** 
  - No incluye infraestructura en la nube; requiere configuraci√≥n adicional para escalabilidad.
  - Requiere personalizaci√≥n para despliegue y mantenimiento de modelos en producci√≥n.

#### Amazon SageMaker
- **Pros:** 
  - Soluci√≥n integral gestionada con integraci√≥n profunda en AWS.
  - Ofrece despliegue de modelos a gran escala, almacenamiento de artefactos, experimentaci√≥n y monitorizaci√≥n.
  - Funciones avanzadas como entrenamiento distribuido, AutoML y despliegue a endpoints.

- **Contras:** 
  - Puede resultar costoso a medida que los proyectos escalan.
  - Depende completamente del ecosistema de AWS, lo que limita la flexibilidad.

#### Azure Machine Learning
- **Pros:** 
  - Integraci√≥n profunda con Azure DevOps y otros servicios de Microsoft.
  - Gran soporte para entrenamientos distribuidos, Kubernetes y CI/CD.
  - Ofrece herramientas de visualizaci√≥n para monitorizaci√≥n de experimentos y modelos.

- **Contras:** 
  - Costoso para grandes implementaciones, especialmente si se requiere entrenamiento intensivo en recursos.
  - Limitado a usuarios y organizaciones dentro del ecosistema de Microsoft Azure.

#### Google AI Platform
- **Pros:** 
  - Integraci√≥n nativa con GCP, BigQuery, y Dataflow para flujos de trabajo de datos.
  - Compatible con Google Kubernetes Engine para despliegues escalables.
  - Facilita experimentaci√≥n y despliegue con servicios gestionados y AutoML.

- **Contras:** 
  - La flexibilidad de personalizaci√≥n es limitada fuera de GCP.
  - Costos pueden aumentar r√°pidamente con el uso de infraestructuras avanzadas como TPU.

### Recomendaci√≥n

1. **MLflow** es ideal para proyectos de machine learning donde se requiere flexibilidad, personalizaci√≥n y una soluci√≥n open-source independiente de la nube.
2. **Amazon SageMaker** es adecuado para empresas ya integradas en AWS que buscan una soluci√≥n completa y gestionada con escalabilidad en la nube.
3. **Azure Machine Learning** es la mejor opci√≥n para usuarios de Microsoft Azure que requieren un entorno de CI/CD y una gesti√≥n integral de experimentos y modelos.
4. **Google AI Platform** es una excelente elecci√≥n para proyectos intensivos en datos y usuarios de GCP que buscan aprovechar el ecosistema Google para an√°lisis y escalabilidad.

Cada opci√≥n permite una personalizaci√≥n adecuada, aunque la dependencia de un ecosistema en la nube espec√≠fico puede ser una consideraci√≥n cr√≠tica para proyectos a largo plazo.

## Demo con la Herramienta MLFlow

- https://github.com/AndreaLlerena2003/mlOps-mlFlow

## Video de Demostraci√≥n
- https://streamyard.com/zxwudefhzyxh

  
# Documentaci√≥n: Demo de MLflow con Clasificaci√≥n de Im√°genes

Esta demo utiliza **MLflow** para rastrear experimentos de Machine Learning con un modelo de clasificaci√≥n de im√°genes basado en TensorFlow y MobileNet. El flujo incluye la descarga de im√°genes, preprocesamiento, entrenamiento y registro del modelo.

## Objetivos
1. Utilizar MLflow para gestionar el seguimiento de experimentos.
2. Entrenar un modelo con TensorFlow (MobileNet) para clasificar entre dos clases de im√°genes.
3. Automatizar la descarga de datos y preprocesamiento con herramientas como `bing_image_downloader`.

## Requisitos

- `mlflow`
- `tensorflow`
- `bing_image_downloader`
- `matplotlib`
- `requests`

## Paso 1: Importaci√≥n de Librer√≠as

En esta etapa, importamos las librer√≠as necesarias para el proyecto, incluyendo TensorFlow, Keras, MLflow y otras herramientas √∫tiles como `matplotlib` para la visualizaci√≥n y `bing_image_downloader` para descargar im√°genes.

## Paso 2: Descarga Autom√°tica de Im√°genes

Usamos la librer√≠a `bing_image_downloader` para buscar im√°genes de las categor√≠as "perro" y "gato" desde Bing. Estas im√°genes se almacenan en directorios separados llamados `dataset/dog` y `dataset/cat`. Esto nos proporciona un conjunto de datos para entrenar el modelo de clasificaci√≥n.

### C√≥digo para descargar im√°genes

El proceso de descarga se realiza con la siguiente funci√≥n:

- Se define la funci√≥n `download_images`, que toma un t√©rmino de b√∫squeda, el l√≠mite de im√°genes a descargar y la ubicaci√≥n de salida donde se almacenar√°n las im√°genes.
- La funci√≥n descarga im√°genes de Bing y las guarda en el directorio especificado.

## Paso 3: Preprocesamiento de Datos

Antes de entrenar el modelo, es necesario validar las im√°genes descargadas para asegurarse de que sean de tipo `jpeg` o `png`. Las im√°genes que no cumplan con estos requisitos ser√°n eliminadas.

### Validaci√≥n de Im√°genes

Se utiliza la funci√≥n `validate_images` que recorre todos los archivos en un directorio dado, verifica el tipo de imagen con `imghdr` y elimina las que no sean de los tipos v√°lidos.

## Paso 4: Configuraci√≥n y Entrenamiento del Modelo

En este paso, utilizamos un modelo preentrenado de MobileNet, que es un modelo eficiente para clasificaci√≥n de im√°genes. Este modelo se ajusta para trabajar con un problema de clasificaci√≥n binaria (perro o gato).

### Creaci√≥n del Modelo

Se usa MobileNet como base, con su capa superior eliminada (`include_top=False`). Luego se agrega una capa de `GlobalAveragePooling2D` y una capa densa con activaci√≥n `sigmoid` para la clasificaci√≥n binaria. El modelo es compilado con el optimizador `adam` y la funci√≥n de p√©rdida `binary_crossentropy`.

## Paso 5: Configuraci√≥n de MLflow

MLflow es una herramienta de gesti√≥n de experimentos que nos permite registrar, rastrear y gestionar modelos de machine learning. En esta etapa, configuramos MLflow para que pueda rastrear nuestros experimentos y registrar el modelo entrenado.

### Configuraci√≥n de MLflow

Se establece la URI de seguimiento de MLflow a un servidor local (`http://localhost:5000`) y se define un experimento llamado "Clasificaci√≥n de Im√°genes". Esto permite organizar y visualizar los experimentos realizados.

### Registro del Experimento

Durante el entrenamiento, se inicia una nueva ejecuci√≥n con `mlflow.start_run()`, se entrena el modelo con los datos de entrenamiento y validaci√≥n, y se registran los par√°metros y m√©tricas relevantes, como la precisi√≥n del modelo y el n√∫mero de √©pocas. Tambi√©n se guarda el modelo entrenado usando `mlflow.keras.log_model`.

## Paso 6: Evaluaci√≥n del Modelo

Una vez que el modelo ha sido entrenado, evaluamos su rendimiento usando un conjunto de datos de prueba. En esta etapa, se calcula la precisi√≥n del modelo para obtener una m√©trica que nos indique qu√© tan bien se desempe√±a en el problema de clasificaci√≥n de im√°genes.

### Evaluaci√≥n y Visualizaci√≥n

El modelo se eval√∫a usando el m√©todo `evaluate`, y se imprime la precisi√≥n obtenida en el conjunto de prueba. Esta m√©trica es clave para entender el rendimiento del modelo.

## Resultados Esperados

- **Clasificaci√≥n exitosa entre "perro" y "gato"**: El modelo deber√≠a ser capaz de diferenciar entre im√°genes de perros y gatos con una buena precisi√≥n.
- **Registro del modelo en MLflow**: El modelo entrenado se registra correctamente en MLflow, lo que permite futuras predicciones y experimentos.
- **Visualizaci√≥n de m√©tricas clave**: A trav√©s de MLflow, podemos visualizar la precisi√≥n del modelo y otros par√°metros importantes durante el entrenamiento.

## Conclusiones

Este proyecto demuestra c√≥mo integrar MLflow en un flujo t√≠pico de Machine Learning, facilitando el seguimiento de experimentos y la gesti√≥n de modelos. Adem√°s, muestra c√≥mo utilizar un modelo preentrenado como MobileNet para abordar un problema de clasificaci√≥n binaria de im√°genes de manera eficiente.

















